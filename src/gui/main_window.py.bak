import os
import os,time
import tkinter as tk
from tkinter import ttk
import threading
import time
from datetime import datetime
from tkinter import filedialog
from PIL import Image, ImageTk
from diffusers.models import AutoencoderKL
import torch
from diffusers import StableDiffusionXLPipeline
from src.modules.refiner_module import refine_image
from src.modules import refiner_module
import json
import numpy as np
import torchvision.transforms as T
try:
    from src.nodes.cosmos_text_to_video import CosmosTextToVideo
except Exception as _cosmos_err:
    print(f"[Cosmos] Deferred load (will stay disabled): {_cosmos_err}")
    CosmosTextToVideo = None
from src.modules.utils.telemetry import log_event

import sys

from src.config.config_paths import UPSCALE_MODEL_PATHS

from torchvision import transforms
from diffusers import (
    EulerDiscreteScheduler,
    DPMSolverMultistepScheduler,
    PNDMScheduler,
    DDIMScheduler,
    LCMScheduler
)
# (Removed duplicate CosmosTextToVideo import block)

OUTPUT_DIR = r"F:\SoftwareDevelopment\AI Models Image\AIGenerator\outputs"
REFINED_DIR = os.path.join(OUTPUT_DIR, "images", "refined")
BIN_LOG = r"F:\SoftwareDevelopment\AI Models Image\AIGenerator\logs\bin_log.txt"
MODEL_ROOT = r"F:\SoftwareDevelopment\AI Models Image\AIGenerator\models\text_to_image"

def discover_models():
    models = {}
    for root, dirs, files in os.walk(MODEL_ROOT):
        for d in dirs:
            models[d] = os.path.join(root, d)
        for f in files:
            if f.endswith(".safetensors"):
                name = os.path.splitext(f)[0]
                models[name] = os.path.join(root, f)
    return models

MODEL_CAPABILITIES = {
    "SDXL 1.0": {"refiner": True},
    "SDXL 1.5": {"refiner": True},
    "SD3.5 TensorRT": {"refiner": False},
    "DreamShaper XL Turbo v2": {"refiner": True}
}

NODE_CLASS_MAPPINGS = {
    "CosmosTextToVideo": CosmosTextToVideo
}

def get_cuda_vram():
    try:
        props = torch.cuda.get_device_properties(0)
        total = props.total_memory // 1024**2
        used = torch.cuda.memory_allocated() // 1024**2
        return used, total
    except Exception as e:
        print(f"[Telemetry] CUDA VRAM fetch failed: {e}")
        return 0, 0

def get_model_metadata(path):
    return {
        "size_mb": round(os.path.getsize(path) / (1024 * 1024), 2),
        "last_modified": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(os.path.getmtime(path)))
    }

def log_model_switch(name, path):
    try:
        log_event({"event":"ModelSwitch","model":name,"path":path,"timestamp":datetime.now().isoformat()})
    except Exception:
        with open(r"F:\SoftwareDevelopment\AI Models Image\AIGenerator\logs\model_switch.log", "a", encoding="utf-8") as log:
            log.write(f"[{datetime.now()}] Switched to {name} -> {path}\n")

class MainWindow(tk.Frame):
    def __init__(self, root, sd35_sessions=None):
        super().__init__(root)
        self.root = root
        self.sd35_sessions = sd35_sessions or {}
        self.status_text = tk.StringVar(value="üß™ Refiner: Inactive")
        self.progress_var = tk.DoubleVar(master=self.root, value=0)
        self.resolution_var = tk.StringVar(value="1024x1024")
        try:
            from src.modules.refiner_module import REFINER_AVAILABLE
            initial_status = "üß† Refiner: Active" if REFINER_AVAILABLE else "üß™ Refiner: Fallback"
        except Exception:
            initial_status = "‚ö†Ô∏è Refiner: Error"
        self.status_text.set(initial_status)
        self.setup_gui()
        self.build_prompt_ui()
        # Safely instantiate cosmos node (avoid circular import issues earlier)
        try:
            self.cosmos_node = CosmosTextToVideo()
        except Exception as e:
            self.cosmos_node = None
            print(f"[Cosmos] Init failed: {e}")
        threading.Thread(target=self._background_preflight_and_apply, daemon=True).start()
        threading.Thread(target=self._background_preload_refiner, daemon=True).start()

    def _background_preflight_and_apply(self):
        try:
            preflight = None
            try:
                preflight = self.sd35_sessions.get("preflight") if isinstance(self.sd35_sessions, dict) else None
            except Exception:
                preflight = None
            if preflight and isinstance(preflight, dict):
                missing = preflight.get("missing_files", []) or []
                if missing:
                    msg = f"Preflight: {len(missing)} missing files"
                    try: self.root.after(0, lambda: self.time_label.config(text=msg))
                    except Exception: pass
                    log_event({"event": "PreflightMissingFiles", "count": len(missing), "timestamp": datetime.now().isoformat()})
                else:
                    try: self.root.after(0, lambda: self.time_label.config(text="Preflight OK"))
                    except Exception: pass
                    log_event({"event": "PreflightOK", "timestamp": datetime.now().isoformat()})
                return
            from src.modules.preflight_check import run_preflight
            result = run_preflight()
            if isinstance(result, dict):
                missing = result.get("missing_files") or []
                if missing:
                    msg = f"Preflight: {len(missing)} missing files"
                    try: self.root.after(0, lambda: self.time_label.config(text=msg))
                    except Exception: pass
                    log_event({"event": "PreflightMissingFiles", "count": len(missing), "timestamp": datetime.now().isoformat()})
                else:
                    try: self.root.after(0, lambda: self.time_label.config(text="Preflight OK"))
                    except Exception: pass
                    log_event({"event": "PreflightOK", "timestamp": datetime.now().isoformat()})
        except Exception as e:
            log_event({"event": "PreflightRunFailed", "error": str(e), "timestamp": datetime.now().isoformat()})

    def _background_preload_refiner(self):
        try:
            device = "cuda" if torch.cuda.is_available() else "cpu"
            try:
                refiner_module.load_refiner(device=device, force_reload=False)
                log_event({"event": "RefinerWarmup", "status": "ready", "device": device, "timestamp": datetime.now().isoformat()})
                try: self.root.after(0, lambda: self.time_label.config(text="Refiner warmed"))
                except Exception: pass
            except Exception as e:
                if device != "cpu":
                    try:
                        refiner_module.load_refiner(device="cpu", force_reload=False)
                        log_event({"event": "RefinerWarmup", "status": "cpu_fallback", "timestamp": datetime.now().isoformat()})
                        try: self.root.after(0, lambda: self.time_label.config(text="Refiner warmed (CPU)"))
                        except Exception: pass
                        return
                    except Exception:
                        pass
                log_event({"event": "RefinerWarmupFailed", "error": str(e), "timestamp": datetime.now().isoformat()})
        except Exception as e:
            log_event({"event": "RefinerWarmupThreadError", "error": str(e), "timestamp": datetime.now().isoformat()})

    def threaded_generate(self):
        threading.Thread(target=self.generate_image, daemon=True).start()

    def generate_image(self):
        sampler_name = self.sampler_var.get()
        scheduler_cls = self.sampler_map.get(sampler_name, EulerDiscreteScheduler)
        selected = self.selected_model.get()
        _ = self.model_paths.get(selected)
        if not hasattr(self, "pipe") or self.pipe is None:
            print("‚ùå Pipeline not initialized. Aborting generation.")
            return
        self.update_telemetry_status("üöÄ Image generation started")
        self.start_progress_bar()
        self.refine_button.config(state="disabled")
        self.refine_button.config(text="üß™ Refine")
        self.pipe.scheduler = scheduler_cls.from_config(self.pipe.scheduler.config)
        self.canvas.delete("all")
        self.canvas.image = None
        if hasattr(self, "progress_bar"):
            self.progress_bar.config(mode="determinate", maximum=100)
        self.progress_var.set(0)
        self.update_telemetry_status("Image generation started...")
        prompt = self.prompt_entry.get("1.0", "end").strip()
        negative = self.negative_prompt_entry.get("1.0", "end").strip()
        try:
            result = self.pipe(
                prompt=prompt,
                negative_prompt=negative,
                num_inference_steps=30,
                guidance_scale=7.5,
                callback_on_step_end=self.progress_callback
            )
            if not result or not result.images:
                print("‚ùå No image returned from pipeline.")
                return
            image = result.images[0]
            os.makedirs("output", exist_ok=True)
            image.save("output/generated_image.png")
            self.tk_image = ImageTk.PhotoImage(image)
            self.canvas.create_image(0, 0, anchor="nw", image=self.tk_image)
            self.canvas.image = self.tk_image
            self.reset_progress_bar()
            self.refine_button.config(state="normal")
            self.update_telemetry_status("‚úÖ Image generation complete")
        except Exception as e:
            print(f"[Error] Image generation failed: {e}")
            import traceback; traceback.print_exc()
            self.update_telemetry_status("‚ùå Generation error")

    def generate_video(self):
        selected = self.selected_model.get()
        _ = self.model_paths.get(selected)
        if not hasattr(self, "cosmos_node") or self.cosmos_node is None:
            self.update_telemetry_status("Cosmos not ready.")
            return
        prompt = self.prompt_entry.get("1.0", "end").strip()
        frame_count = 16
        width, height = 512, 512
        self.generated_frames = []
        self.update_telemetry_status("üéûÔ∏è Cosmos video generation started...")
        def on_frame(frame): self.generated_frames.append(frame)
        try:
            # NOTE: If your CosmosTextToVideo class lacks threaded_generate, adapt here.
            frame0, save_path = self.cosmos_node.generate(prompt, frame_count, width, height)
            self.generated_frames.append(frame0)
            self.update_telemetry_status(f"Cosmos frame saved: {os.path.basename(save_path)}")
            self.root.after(500, self.play_video_preview)
        except Exception as e:
            print(f"[Error] Cosmos generate failed: {e}")
            self.telemetry_label.config(text=f"[Error] Cosmos generate failed: {e}")

    def upload_image(self):
        file_path = filedialog.askopenfilename(
            title="Select Image",
            filetypes=[("Image Files", "*.png *.jpg *.jpeg *.bmp *.webp")]
        )
        if file_path:
            try:
                img = Image.open(file_path)
                self.uploaded_image = img
                preview = img.resize((256, 256))
                img_tk = ImageTk.PhotoImage(preview)
                self.preview_canvas(img_tk)
                self.time_label.config(text=f"Uploaded: {os.path.basename(file_path)}")
                print(f"üì§ Image uploaded: {file_path}")
            except Exception as e:
                self.time_label.config(text=f"Upload failed: {e}")
                print(f"‚ùå Upload error: {e}")

    def build_prompt_ui(self):
        # (Existing UI elements...)

        # New frames for resolution and steps/guidance controls
        self.advanced_frame = tk.LabelFrame(self, text="Advanced Settings", padx=10, pady=10)
        self.advanced_frame.pack(padx=10, pady=10, fill="x")

        # Width and Height
        res_label = tk.Label(self.advanced_frame, text="Resolution:")
        res_label.grid(row=0, column=0, sticky="e")
        self.width_var = tk.IntVar(value=512)
        self.height_var = tk.IntVar(value=512)
        width_entry = tk.Entry(self.advanced_frame, textvariable=self.width_var, width=5)
        height_entry = tk.Entry(self.advanced_frame, textvariable=self.height_var, width=5)
        width_entry.grid(row=0, column=1, padx=5, pady=5)
        height_entry.grid(row=0, column=2, padx=5, pady=5)
        width_label = tk.Label(self.advanced_frame, text="x")
        width_label.grid(row=0, column=3, padx=5, pady=5)
        preset_res_button = tk.Button(self.advanced_frame, text="4:3 Preset", command=self.set_preset_res)
        preset_res_button.grid(row=0, column=4, padx=5, pady=5)

        # Inference Steps
        steps_label = tk.Label(self.advanced_frame, text="Inference Steps:")
        steps_label.grid(row=1, column=0, sticky="e")
        self.steps_var = tk.IntVar(value=30)
        steps_scale = tk.Scale(self.advanced_frame, variable=self.steps_var, from_=10, to=150, orient="horizontal")
        steps_scale.grid(row=1, column=1, columnspan=3, sticky="ew", padx=5, pady=5)

        # Guidance Scale
        guidance_label = tk.Label(self.advanced_frame, text="Guidance Scale:")
        guidance_label.grid(row=2, column=0, sticky="e")
        self.guidance_var = tk.DoubleVar(value=7.5)
        guidance_scale = tk.Scale(self.advanced_frame, variable=self.guidance_var, from_=1.0, to=20.0, resolution=0.1, orient="horizontal")
        guidance_scale.grid(row=2, column=1, columnspan=3, sticky="ew", padx=5, pady=5)

        # Update button to apply these settings
        apply_button = tk.Button(self.advanced_frame, text="Apply Settings", command=self.apply_gen_settings)
        apply_button.grid(row=3, column=0, columnspan=5, pady=10)

        # (Existing elements...)

    def set_preset_res(self):
        """Set resolution to a common preset (4:3 aspect ratio)."""
        self.width_var.set(800)
        self.height_var.set(600)

    def apply_gen_settings(self):
        """Apply the advanced generation settings."""
        width = self.width_var.get()
        height = self.height_var.get()
        num_steps = self.steps_var.get()
        guidance = self.guidance_var.get()
        # You can add more validation here as needed
        print(f"Applying settings - Width: {width}, Height: {height}, Steps: {num_steps}, Guidance: {guidance}")
        # Update some internal state if necessary...

    def generate_image(self):
        sampler_name = self.sampler_var.get()
        scheduler_cls = self.sampler_map.get(sampler_name, EulerDiscreteScheduler)
        selected = self.selected_model.get()
        _ = self.model_paths.get(selected)
        if not hasattr(self, "pipe") or self.pipe is None:
            print("‚ùå Pipeline not initialized. Aborting generation.")
            return
        self.update_telemetry_status("üöÄ Image generation started")
        self.start_progress_bar()
        self.refine_button.config(state="disabled")
        self.refine_button.config(text="üß™ Refine")
        self.pipe.scheduler = scheduler_cls.from_config(self.pipe.scheduler.config)
        self.canvas.delete("all")
        self.canvas.image = None
        if hasattr(self, "progress_bar"):
            self.progress_bar.config(mode="determinate", maximum=100)
        self.progress_var.set(0)
        self.update_telemetry_status("Image generation started...")
        prompt = self.prompt_entry.get("1.0", "end").strip()
        negative = self.negative_prompt_entry.get("1.0", "end").strip()
        width = self.width_var.get()
        height = self.height_var.get()
        num_steps = self.steps_var.get()
        guidance = self.guidance_var.get()
        try:
            result = self.pipe(
                prompt=prompt,
                negative_prompt=negative,
                num_inference_steps=num_steps,
                guidance_scale=guidance,
                width=width,
                height=height,
                callback_on_step_end=self.progress_callback
            )
            if not result or not result.images:
                print("‚ùå No image returned from pipeline.")
                return
            image = result.images[0]
            os.makedirs("output", exist_ok=True)
            image.save("output/generated_image.png")
            self.tk_image = ImageTk.PhotoImage(image)
            self.canvas.create_image(0, 0, anchor="nw", image=self.tk_image)
            self.canvas.image = self.tk_image
            self.reset_progress_bar()
            self.refine_button.config(state="normal")
            self.update_telemetry_status("‚úÖ Image generation complete")
        except Exception as e:
            print(f"[Error] Image generation failed: {e}")
            import traceback; traceback.print_exc()
            self.update_telemetry_status("‚ùå Generation error")


print("=== SDXL Cockpit Preflight Check ===")

            device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"[Preflight] Using device: {device}")
            if device == "cuda":
                print(f"[Preflight] CUDA VRAM: {get_cuda_vram()} MB")
            from src.modules.refiner_module import REFINER_AVAILABLE
            if not REFINER_AVAILABLE:
                print("[Preflight] Warning: Refiner not available")
            self.time_label.config(text="Preflight check complete")
        except Exception as e:
            print(f"[Preflight] Error: {e}")
            self.time_label.config(text=f"Preflight error: {e}")

































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































