import torch
import numpy as np
from PIL import Image
from pathlib import Path
from diffusers import StableDiffusionPipeline
from transformers import pipeline
import subprocess
import sys

# Optional: log output to file
# sys.stdout = open("telemetry/sanity_log.txt", "w")

print("ğŸ”§ GPU Available:", torch.cuda.is_available())
print("ğŸ§  CUDA Version:", torch.version.cuda)
print("ğŸ§® Torch Version:", torch.__version__)

# ğŸ§¼ Dependency health check
try:
    subprocess.run(["pip", "check"], check=True)
    print("âœ… Dependencies are healthy")
except subprocess.CalledProcessError:
    print("âŒ Dependency issues detected")

# ğŸ”¬ Test tensor creation on GPU
try:
    dummy = torch.randn(1, 3, 512, 512).to("cuda")
    print("âœ… Torch tensor created on GPU")
except Exception as e:
    print("âŒ Torch tensor error:", e)

# ğŸ¨ Test Stable Diffusion pipeline
try:
    pipe = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16,
        cache_dir="models/"
    )
    pipe.to("cuda")
    print("âœ… Diffusers pipeline loaded")
    # Validate model path
    if not Path(pipe.config._name_or_path).exists():
        print("âš ï¸ Model path not found:", pipe.config._name_or_path)
except Exception as e:
    print("âŒ Diffusers error:", e)

# ğŸ§  Test Transformers pipeline
try:
    nlp = pipeline("sentiment-analysis", device=0 if torch.cuda.is_available() else -1)
    result = nlp("This cockpit is legendary.")
    print("âœ… Transformers pipeline loaded:", result)
except Exception as e:
    print("âŒ Transformers error:", e)

# ğŸ”¼ Real-ESRGAN skipped
print("â­ï¸ Real-ESRGAN test skipped â€” module not initialized")

# ğŸ–¼ï¸ Test image I/O
try:
    img = Image.fromarray(np.uint8(np.random.rand(512, 512, 3) * 255))
    img.save("test_image.png")
    print("âœ… PIL image saved")
except Exception as e:
    print("âŒ PIL error:", e)
